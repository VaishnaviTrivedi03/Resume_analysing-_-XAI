{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d31fd8-1790-4a67-9d6e-c4280f88770f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhigh_level\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_text\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_text_from_pdf\u001b[39m(file_path):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfminer'"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    try:\n",
    "        text = extract_text(file_path)  # Extract text from PDF\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function with a PDF file\n",
    "pdf_file_path = \"demo_resume.pdf\"\n",
    "extracted_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "if extracted_text:\n",
    "    print(\"Extracted Text:\\n\", extracted_text)\n",
    "else:\n",
    "    print(\"Failed to extract text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207e450-18a4-4532-bb6f-129a386b10b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extracted_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m details\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m basic_details \u001b[38;5;241m=\u001b[39m extract_basic_details(\u001b[43mextracted_text\u001b[49m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasic Details:\u001b[39m\u001b[38;5;124m\"\u001b[39m, basic_details)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extracted_text' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_basic_details(text):\n",
    "    details = {\n",
    "        \"Name\": None,\n",
    "        \"Phone Number\": None,\n",
    "        \"Email\": None,\n",
    "        \"LinkedIn\": None,\n",
    "        \"GitHub\": None,\n",
    "    }\n",
    "    \n",
    "    # Extract email\n",
    "    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
    "    details[\"Email\"] = email_match.group(0) if email_match else \"Not Found\"\n",
    "    \n",
    "    # Extract phone number\n",
    "    phone_match = re.search(r\"\\b\\d{10}\\b|\\+\\d{1,3}\\s?\\d{10}\\b\", text)\n",
    "    details[\"Phone Number\"] = phone_match.group(0) if phone_match else \"Not Found\"\n",
    "    \n",
    "    # Extract LinkedIn\n",
    "    linkedin_match = re.search(r\"(https?://)?(www\\.)?linkedin\\.com/in/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"LinkedIn\"] = linkedin_match.group(0) if linkedin_match else \"Not Found\"\n",
    "    \n",
    "    # Extract GitHub\n",
    "    github_match = re.search(r\"(https?://)?(www\\.)?github\\.com/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"GitHub\"] = github_match.group(0) if github_match else \"Not Found\"\n",
    "    \n",
    "    # Extract name (assumes first word in text is the name)\n",
    "    lines = text.splitlines()\n",
    "    details[\"Name\"] = lines[0].strip() if lines else \"Not Found\"\n",
    "\n",
    "    return details\n",
    "\n",
    "# Example usage\n",
    "basic_details = extract_basic_details(extracted_text)\n",
    "print(\"Basic Details:\", basic_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6b4248-c123-434f-9c1d-f61481ed7dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills: {'Programming Languages': ['Python', 'C', 'C++', 'Java', 'PHP'], 'Web Technologies': ['HTML', 'CSS'], 'Tools & Platforms': ['GitHub', 'Streamlit']}\n"
     ]
    }
   ],
   "source": [
    "def extract_skills(text):\n",
    "    skills = {\n",
    "        \"Programming Languages\": [],\n",
    "        \"Web Technologies\": [],\n",
    "        \"Tools & Platforms\": []\n",
    "    }\n",
    "\n",
    "    # Programming Languages\n",
    "    prog_lang_match = re.search(r\"(?i)Programming Languages: (.*?)(?=\\n)\", text)\n",
    "    if prog_lang_match:\n",
    "        skills[\"Programming Languages\"] = [lang.strip() for lang in prog_lang_match.group(1).split(\",\")]\n",
    "\n",
    "    # Web Technologies\n",
    "    web_tech_match = re.search(r\"(?i)Web Technologies: (.*?)(?=\\n)\", text)\n",
    "    if web_tech_match:\n",
    "        skills[\"Web Technologies\"] = [tech.strip() for tech in web_tech_match.group(1).split(\",\")]\n",
    "\n",
    "    # Tools & Platforms\n",
    "    tools_match = re.search(r\"(?i)Tools & Platforms: (.*?)(?=\\n)\", text)\n",
    "    if tools_match:\n",
    "        skills[\"Tools & Platforms\"] = [tool.strip() for tool in tools_match.group(1).split(\",\")]\n",
    "\n",
    "    return skills\n",
    "\n",
    "# Example usage\n",
    "skills_details = extract_skills(extracted_text)\n",
    "print(\"Skills:\", skills_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a3927a-7901-4475-b976-1db2b2d82343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education Section Found:\n",
      " Krupanidhi Degree College \n",
      "Bachelor of Computer Applications  \n",
      "\n",
      "2021 - 2024 \n",
      "CGPA: 9.41/10 \n",
      "\n",
      "Krupanidhi PRE-University College                                                                                     2019-2021 \n",
      "PUC \n",
      "\n",
      "Percentage: 80.66% \n",
      "\n",
      "Sophia High School                                                                                                                 2018-2019 \n",
      "SSLC \n",
      "\n",
      "Percentage: 66.72%\n",
      "Matches Found: [('Krupanidhi Degree College \\nBachelor of Computer Applications', 'CGPA', '9.41')]\n",
      "Final Degree and CGPA Output: [{'Degree': 'Bachelor of Computer Applications', 'CGPA': '9.41'}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_degree_and_cgpa(text):\n",
    "    education = []\n",
    "\n",
    "    # Step 1: Extract the Education section\n",
    "    education_section_pattern = r\"Education\\s*([\\s\\S]+?)(?=\\n\\s*(?:Skills|Publications|Experience|$))\"\n",
    "    education_section_match = re.search(education_section_pattern, text, re.DOTALL)\n",
    "    if education_section_match:\n",
    "        education_section = education_section_match.group(1).strip()\n",
    "        print(\"Education Section Found:\\n\", education_section)  # Debugging output\n",
    "    else:\n",
    "        print(\"No Education section found!\")\n",
    "        return education  # Return empty if no education section is found\n",
    "\n",
    "    # Step 2: Match the Degree and CGPA specifically\n",
    "    degree_cgpa_pattern = r\"([A-Za-z\\s]+(?:College|School|Institute|University)[\\s\\S]*?)\\s*[\\n\\r]+[0-9]{4} - [0-9]{4}\\s*[\\n\\r]+(CGPA)\\s*[:]*\\s*(\\d+\\.?\\d*)\"\n",
    "    matches = re.findall(degree_cgpa_pattern, education_section)\n",
    "    print(\"Matches Found:\", matches)  # Debugging output\n",
    "\n",
    "    # Step 3: Process each match and extract degree and CGPA\n",
    "    for match in matches:\n",
    "        institution_with_degree = match[0].strip()\n",
    "        grade_type = match[1].strip()\n",
    "        grade = match[2].strip()\n",
    "\n",
    "        # Fixing the extraction of the full degree name\n",
    "        degree_match = re.search(r\"(Bachelor of Computer Applications|Bachelor's Degree|Master's Degree|MCA|PhD)\", institution_with_degree)\n",
    "        degree = degree_match.group(0).strip() if degree_match else \"Degree not found\"\n",
    "\n",
    "        # Append to final output list\n",
    "        education.append({\n",
    "            \"Degree\": degree,\n",
    "            \"CGPA\": grade,\n",
    "        })\n",
    "\n",
    "    return education\n",
    "\n",
    "# Define the extracted_text variable\n",
    "extracted_text = \"\"\"\n",
    "Vivek R\n",
    "\n",
    "vivekgowda480@gmail.com  |\n",
    "\n",
    "9148375755\n",
    "\n",
    "github.com/Vivektheprogrammer  |\n",
    "\n",
    "linkedin.com/in/vivekr  \n",
    "\n",
    "Skills\n",
    "\n",
    "Programming Languages: Python, C, C++, Java, PHP \n",
    "Web Technologies: HTML, CSS \n",
    "Tools & Platforms: GitHub, Streamlit \n",
    "\n",
    "Education\n",
    "\n",
    "Krupanidhi Degree College \n",
    "Bachelor of Computer Applications  \n",
    "\n",
    "2021 - 2024 \n",
    "CGPA: 9.41/10 \n",
    "\n",
    "Krupanidhi PRE-University College                                                                                     2019-2021 \n",
    "PUC \n",
    "\n",
    "Percentage: 80.66% \n",
    "\n",
    "Sophia High School                                                                                                                 2018-2019 \n",
    "SSLC \n",
    "\n",
    "Percentage: 66.72%\n",
    "\"\"\"\n",
    "\n",
    "# Call the function\n",
    "education_details = extract_degree_and_cgpa(extracted_text)\n",
    "print(\"Final Degree and CGPA Output:\", education_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f01ade-c43e-4bbf-a599-566e6e388523",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python313/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample resume text\n",
    "resume_text = \"\"\"\n",
    "Technical Skills:\n",
    "- Proficient in Python, Java, and C++.\n",
    "- Experienced with Machine Learning, TensorFlow, and Scikit-Learn.\n",
    "- Knowledge of Web Development frameworks: Django, React, Node.js.\n",
    "- Familiar with database management systems: SQL, MongoDB.\n",
    "\"\"\"\n",
    "\n",
    "# Define a list of common programming languages and tools\n",
    "skills_list = [\n",
    "    'Python', 'Java', 'C++', 'JavaScript', 'SQL', 'Machine Learning', 'TensorFlow', 'Scikit-Learn', \n",
    "    'Django', 'React', 'Node.js', 'MongoDB', 'Git', 'HTML', 'CSS', 'Ruby', 'PHP', 'Swift', 'Kotlin'\n",
    "]\n",
    "\n",
    "# Function to extract skills from resume text\n",
    "def extract_skills(text, skills):\n",
    "    # Clean the text (optional, based on your need)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Initialize an empty list for the skills found\n",
    "    extracted_skills = []\n",
    "\n",
    "    # Search for each skill in the list\n",
    "    for skill in skills:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text):\n",
    "            extracted_skills.append(skill)\n",
    "\n",
    "    return extracted_skills\n",
    "\n",
    "# Extract skills from resume\n",
    "extracted_skills = extract_skills(resume_text, skills_list)\n",
    "\n",
    "# Output extracted skills\n",
    "print(\"Extracted Skills:\", extracted_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93421a60-63fe-46f2-90eb-2983bb88a73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Required_Matches': ['Python',\n",
       "  'SQL',\n",
       "  'Machine Learning',\n",
       "  'TensorFlow',\n",
       "  'Scikit-Learn',\n",
       "  'MongoDB'],\n",
       " 'Preferred_Matches': ['Django', 'React', 'Node.js', 'Java'],\n",
       " 'Total_Score': 80,\n",
       " 'Relevance_Percentage': 100.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the skills\n",
    "required_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"TensorFlow\", \"Scikit-Learn\", \"MongoDB\"]\n",
    "preferred_skills = [\"Django\", \"React\", \"Node.js\", \"Java\"]\n",
    "\n",
    "# Extracted skills from the resume\n",
    "resume_skills = [\"Python\", \"Java\", \"SQL\", \"Machine Learning\", \"TensorFlow\", \"Scikit-Learn\", \"Django\", \"React\", \"Node.js\", \"MongoDB\"]\n",
    "\n",
    "# Calculate matching scores\n",
    "required_matches = [skill for skill in required_skills if skill in resume_skills]\n",
    "preferred_matches = [skill for skill in preferred_skills if skill in resume_skills]\n",
    "\n",
    "# Scoring\n",
    "required_score = len(required_matches) * 10  # 10 points per required skill\n",
    "preferred_score = len(preferred_matches) * 5  # 5 points per preferred skill\n",
    "max_score = len(required_skills) * 10 + len(preferred_skills) * 5\n",
    "\n",
    "# Total score as a percentage\n",
    "total_score = required_score + preferred_score\n",
    "relevance_percentage = (total_score / max_score) * 100\n",
    "\n",
    "# Output results\n",
    "{\n",
    "    \"Required_Matches\": required_matches,\n",
    "    \"Preferred_Matches\": preferred_matches,\n",
    "    \"Total_Score\": total_score,\n",
    "    \"Relevance_Percentage\": relevance_percentage\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8528468-9183-48d9-b8d8-9594b183867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: demo_resume.pdf\n",
      "Processing: shubha_resume t.pdf\n",
      "Processing: vresume.pdf\n",
      "Processing: Yashu_resume.pdf\n",
      "             File Name            Name                            Email  \\\n",
      "0      demo_resume.pdf         Vivek R          vivekgowda480@gmail.com   \n",
      "1     Yashu_resume.pdf    Yashaswini N         yashaswinin348@gmail.com   \n",
      "2          vresume.pdf      VARSHINI J  varshinijayaprabhu500@gmail.com   \n",
      "3  shubha_resume t.pdf  Shubhashree TK          tkshubhashree@gmail.com   \n",
      "\n",
      "        Phone            Required Matches  Projects Count  \\\n",
      "0  9148375755  [Python, Machine Learning]               2   \n",
      "1  7625005860  [Python, Machine Learning]               2   \n",
      "2  7338432985  [Python, Machine Learning]               1   \n",
      "3  9353710273                    [Python]               1   \n",
      "\n",
      "   Research Papers Count  CGPA  Total Score  Relevance Percentage  Rank  \n",
      "0                      3  9.41        154.1             65.574468     1  \n",
      "1                      1  9.69        136.9             58.255319     2  \n",
      "2                      2  9.06        135.6             57.702128     3  \n",
      "3                      2  8.54        120.4             51.234043     4  \n",
      "Results saved to ranked_resumes.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    try:\n",
    "        text = extract_text(file_path)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract basic details\n",
    "def extract_basic_details(text):\n",
    "    details = {\n",
    "        \"Name\": None,\n",
    "        \"Phone Number\": None,\n",
    "        \"Email\": None,\n",
    "        \"LinkedIn\": None,\n",
    "        \"GitHub\": None,\n",
    "    }\n",
    "\n",
    "    # Extract email\n",
    "    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
    "    details[\"Email\"] = email_match.group(0) if email_match else \"Not Found\"\n",
    "\n",
    "    # Extract phone number\n",
    "    phone_match = re.search(r\"\\b\\d{10}\\b|\\+\\d{1,3}\\s?\\d{10}\\b\", text)\n",
    "    details[\"Phone Number\"] = phone_match.group(0) if phone_match else \"Not Found\"\n",
    "\n",
    "    # Extract LinkedIn\n",
    "    linkedin_match = re.search(r\"(https?://)?(www\\.)?linkedin\\.com/in/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"LinkedIn\"] = linkedin_match.group(0) if linkedin_match else \"Not Found\"\n",
    "\n",
    "    # Extract GitHub\n",
    "    github_match = re.search(r\"(https?://)?(www\\.)?github\\.com/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"GitHub\"] = github_match.group(0) if github_match else \"Not Found\"\n",
    "\n",
    "    # Extract name (assumes first line in text is the name)\n",
    "    lines = text.splitlines()\n",
    "    details[\"Name\"] = lines[0].strip() if lines else \"Not Found\"\n",
    "\n",
    "    return details\n",
    "\n",
    "# Function to extract skills from text\n",
    "def extract_skills(text, skills):\n",
    "    # Convert text to lowercase for case-insensitive matching\n",
    "    text = text.lower()\n",
    "\n",
    "    # Initialize an empty list for the skills found\n",
    "    extracted_skills = []\n",
    "\n",
    "    # Search for each skill in the list\n",
    "    for skill in skills:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text):\n",
    "            extracted_skills.append(skill)\n",
    "\n",
    "    return extracted_skills\n",
    "\n",
    "# Function to extract CGPA\n",
    "def extract_cgpa(text):\n",
    "    cgpa_match = re.search(r\"\\bCGPA[:\\s]+(\\d+\\.\\d+)\\b\", text, re.IGNORECASE)\n",
    "    return float(cgpa_match.group(1)) if cgpa_match else 0.0\n",
    "\n",
    "# Function to extract additional criteria (projects, research papers)\n",
    "def extract_additional_criteria(text):\n",
    "    projects_count = len(re.findall(r\"\\bproject\\b\", text, re.IGNORECASE))\n",
    "    research_papers_count = len(re.findall(r\"\\bpublication|research paper\\b\", text, re.IGNORECASE))\n",
    "    return projects_count, research_papers_count\n",
    "\n",
    "# Function to process and rank resumes\n",
    "def process_resumes(resume_folder, required_skills):\n",
    "    results = []\n",
    "\n",
    "    # Iterate over all files in the resume folder\n",
    "    for file_name in os.listdir(resume_folder):\n",
    "        file_path = os.path.join(resume_folder, file_name)\n",
    "        if file_name.endswith(\".pdf\"):  # Ensure it's a PDF file\n",
    "            print(f\"Processing: {file_name}\")\n",
    "\n",
    "            # Extract text from PDF\n",
    "            extracted_text = extract_text_from_pdf(file_path)\n",
    "            if not extracted_text:\n",
    "                print(f\"Failed to extract text from {file_name}\")\n",
    "                continue\n",
    "\n",
    "            # Extract details and skills\n",
    "            basic_details = extract_basic_details(extracted_text)\n",
    "            resume_skills = extract_skills(extracted_text, required_skills)\n",
    "\n",
    "            # Extract additional criteria\n",
    "            projects_count, research_papers_count = extract_additional_criteria(extracted_text)\n",
    "\n",
    "            # Extract CGPA\n",
    "            cgpa = extract_cgpa(extracted_text)\n",
    "\n",
    "            # Calculate scores\n",
    "            required_matches = [skill for skill in required_skills if skill in resume_skills]\n",
    "\n",
    "            required_score = len(required_matches) * 10\n",
    "            additional_score = (projects_count * 5) + (research_papers_count * 10)\n",
    "            cgpa_score = cgpa * 10  # Scale CGPA to a score (e.g., CGPA 9.0 gives 90 points)\n",
    "\n",
    "            total_score = required_score + additional_score + cgpa_score\n",
    "            max_score = (len(required_skills) * 10) + (5 * 5) + (10 * 5) + 100  # Including max CGPA score\n",
    "\n",
    "            # Avoid division by zero\n",
    "            relevance_percentage = (total_score / max_score * 100) if max_score > 0 else 0\n",
    "\n",
    "            # Append result\n",
    "            results.append({\n",
    "                \"File Name\": file_name,\n",
    "                \"Name\": basic_details[\"Name\"],\n",
    "                \"Email\": basic_details[\"Email\"],\n",
    "                \"Phone\": basic_details[\"Phone Number\"],\n",
    "                \"Required Matches\": required_matches,\n",
    "                \"Projects Count\": projects_count,\n",
    "                \"Research Papers Count\": research_papers_count,\n",
    "                \"CGPA\": cgpa,\n",
    "                \"Total Score\": total_score,\n",
    "                \"Relevance Percentage\": relevance_percentage\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    # Rank resumes based on Total Score\n",
    "    df_results = df_results.sort_values(by=\"Total Score\", ascending=False).reset_index(drop=True)\n",
    "    df_results['Rank'] = df_results.index + 1\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# Define required skills\n",
    "required_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"TensorFlow\", \"Scikit-Learn\", \"MongoDB\"]\n",
    "\n",
    "# Folder containing resumes\n",
    "RESUME_FOLDER = \"resumes/\"\n",
    "\n",
    "# Process resumes and rank them\n",
    "ranked_resumes = process_resumes(RESUME_FOLDER, required_skills)\n",
    "\n",
    "# Display results\n",
    "print(ranked_resumes)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "ranked_resumes.to_csv(\"ranked_resumes.csv\", index=False)\n",
    "print(\"Results saved to ranked_resumes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d0986a-08d5-4242-9b97-00258c25b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted skills from job description: ['TensorFlow', 'MongoDB', 'Python', 'Scikit-Learn', 'Machine Learning', 'SQL']\n",
      "Processing: demo_resume.pdf\n",
      "Processing: shubha_resume t.pdf\n",
      "Processing: vresume.pdf\n",
      "Processing: Yashu_resume.pdf\n",
      "             File Name            Name                            Email  \\\n",
      "0      demo_resume.pdf         Vivek R          vivekgowda480@gmail.com   \n",
      "1     Yashu_resume.pdf    Yashaswini N         yashaswinin348@gmail.com   \n",
      "2          vresume.pdf      VARSHINI J  varshinijayaprabhu500@gmail.com   \n",
      "3  shubha_resume t.pdf  Shubhashree TK          tkshubhashree@gmail.com   \n",
      "\n",
      "        Phone            Required Matches  Projects Count  \\\n",
      "0  9148375755  [Python, Machine Learning]               2   \n",
      "1  7625005860  [Python, Machine Learning]               2   \n",
      "2  7338432985  [Python, Machine Learning]               1   \n",
      "3  9353710273                    [Python]               1   \n",
      "\n",
      "   Research Papers Count  CGPA  Total Score  Relevance Percentage  Rank  \n",
      "0                      3  9.41        154.1             65.574468     1  \n",
      "1                      1  9.69        136.9             58.255319     2  \n",
      "2                      2  9.06        135.6             57.702128     3  \n",
      "3                      2  8.54        120.4             51.234043     4  \n",
      "Results saved to ranked_resumes.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    try:\n",
    "        text = extract_text(file_path)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract basic details\n",
    "def extract_basic_details(text):\n",
    "    details = {\n",
    "        \"Name\": None,\n",
    "        \"Phone Number\": None,\n",
    "        \"Email\": None,\n",
    "        \"LinkedIn\": None,\n",
    "        \"GitHub\": None,\n",
    "    }\n",
    "\n",
    "    # Extract email\n",
    "    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
    "    details[\"Email\"] = email_match.group(0) if email_match else \"Not Found\"\n",
    "\n",
    "    # Extract phone number\n",
    "    phone_match = re.search(r\"\\b\\d{10}\\b|\\+\\d{1,3}\\s?\\d{10}\\b\", text)\n",
    "    details[\"Phone Number\"] = phone_match.group(0) if phone_match else \"Not Found\"\n",
    "\n",
    "    # Extract LinkedIn\n",
    "    linkedin_match = re.search(r\"(https?://)?(www\\.)?linkedin\\.com/in/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"LinkedIn\"] = linkedin_match.group(0) if linkedin_match else \"Not Found\"\n",
    "\n",
    "    # Extract GitHub\n",
    "    github_match = re.search(r\"(https?://)?(www\\.)?github\\.com/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"GitHub\"] = github_match.group(0) if github_match else \"Not Found\"\n",
    "\n",
    "    # Extract name (assumes first line in text is the name)\n",
    "    lines = text.splitlines()\n",
    "    details[\"Name\"] = lines[0].strip() if lines else \"Not Found\"\n",
    "\n",
    "    return details\n",
    "\n",
    "# Function to extract skills from text\n",
    "def extract_skills(text, skills):\n",
    "    # Convert text to lowercase for case-insensitive matching\n",
    "    text = text.lower()\n",
    "\n",
    "    # Initialize an empty list for the skills found\n",
    "    extracted_skills = []\n",
    "\n",
    "    # Search for each skill in the list\n",
    "    for skill in skills:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text):\n",
    "            extracted_skills.append(skill)\n",
    "\n",
    "    return extracted_skills\n",
    "\n",
    "# Function to extract CGPA\n",
    "def extract_cgpa(text):\n",
    "    cgpa_match = re.search(r\"\\bCGPA[:\\s]+(\\d+\\.\\d+)\\b\", text, re.IGNORECASE)\n",
    "    return float(cgpa_match.group(1)) if cgpa_match else 0.0\n",
    "\n",
    "# Function to extract additional criteria (projects, research papers)\n",
    "def extract_additional_criteria(text):\n",
    "    projects_count = len(re.findall(r\"\\bproject\\b\", text, re.IGNORECASE))\n",
    "    research_papers_count = len(re.findall(r\"\\bpublication|research paper\\b\", text, re.IGNORECASE))\n",
    "    return projects_count, research_papers_count\n",
    "\n",
    "# Function to extract skills and other criteria from job description\n",
    "def extract_job_description_skills(job_description):\n",
    "    skills = []\n",
    "    \n",
    "    # Extract skills (assuming the skills are mentioned as comma-separated words)\n",
    "    skills_match = re.findall(r\"\\b(?:Python|SQL|Machine Learning|TensorFlow|Scikit-Learn|MongoDB)\\b\", job_description, re.IGNORECASE)\n",
    "    skills = list(set(skills_match))  # Remove duplicates\n",
    "    return skills\n",
    "\n",
    "# Function to process and rank resumes based on job description\n",
    "def process_resumes(resume_folder, job_description):\n",
    "    results = []\n",
    "\n",
    "    # Extract skills from job description\n",
    "    job_skills = extract_job_description_skills(job_description)\n",
    "    print(f\"Extracted skills from job description: {job_skills}\")\n",
    "\n",
    "    # Iterate over all files in the resume folder\n",
    "    for file_name in os.listdir(resume_folder):\n",
    "        file_path = os.path.join(resume_folder, file_name)\n",
    "        if file_name.endswith(\".pdf\"):  # Ensure it's a PDF file\n",
    "            print(f\"Processing: {file_name}\")\n",
    "\n",
    "            # Extract text from PDF\n",
    "            extracted_text = extract_text_from_pdf(file_path)\n",
    "            if not extracted_text:\n",
    "                print(f\"Failed to extract text from {file_name}\")\n",
    "                continue\n",
    "\n",
    "            # Extract details and skills\n",
    "            basic_details = extract_basic_details(extracted_text)\n",
    "            resume_skills = extract_skills(extracted_text, job_skills)\n",
    "\n",
    "            # Extract additional criteria\n",
    "            projects_count, research_papers_count = extract_additional_criteria(extracted_text)\n",
    "\n",
    "            # Extract CGPA\n",
    "            cgpa = extract_cgpa(extracted_text)\n",
    "\n",
    "            # Calculate scores\n",
    "            required_matches = [skill for skill in job_skills if skill in resume_skills]\n",
    "\n",
    "            required_score = len(required_matches) * 10\n",
    "            additional_score = (projects_count * 5) + (research_papers_count * 10)\n",
    "            cgpa_score = cgpa * 10  # Scale CGPA to a score (e.g., CGPA 9.0 gives 90 points)\n",
    "\n",
    "            total_score = required_score + additional_score + cgpa_score\n",
    "            max_score = (len(job_skills) * 10) + (5 * 5) + (10 * 5) + 100  # Including max CGPA score\n",
    "\n",
    "            # Avoid division by zero\n",
    "            relevance_percentage = (total_score / max_score * 100) if max_score > 0 else 0\n",
    "\n",
    "            # Append result\n",
    "            results.append({\n",
    "                \"File Name\": file_name,\n",
    "                \"Name\": basic_details[\"Name\"],\n",
    "                \"Email\": basic_details[\"Email\"],\n",
    "                \"Phone\": basic_details[\"Phone Number\"],\n",
    "                \"Required Matches\": required_matches,\n",
    "                \"Projects Count\": projects_count,\n",
    "                \"Research Papers Count\": research_papers_count,\n",
    "                \"CGPA\": cgpa,\n",
    "                \"Total Score\": total_score,\n",
    "                \"Relevance Percentage\": relevance_percentage\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    # Rank resumes based on Total Score\n",
    "    df_results = df_results.sort_values(by=\"Total Score\", ascending=False).reset_index(drop=True)\n",
    "    df_results['Rank'] = df_results.index + 1\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# Example Job Description\n",
    "job_description = \"\"\"\n",
    "We are looking for a software developer with expertise in Python, SQL, Machine Learning, and TensorFlow.\n",
    "Experience in MongoDB, Scikit-Learn, and building ML models is a plus. A good understanding of data structures and algorithms is required.\n",
    "Projects related to AI and Data Science are highly valued.\n",
    "\"\"\"\n",
    "\n",
    "# Folder containing resumes\n",
    "RESUME_FOLDER = \"resumes/\"\n",
    "\n",
    "# Process resumes and rank them based on the job description\n",
    "ranked_resumes = process_resumes(RESUME_FOLDER, job_description)\n",
    "\n",
    "# Display results\n",
    "print(ranked_resumes)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "ranked_resumes.to_csv(\"ranked_resumes.csv\", index=False)\n",
    "print(\"Results saved to ranked_resumes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729161a-ceda-4551-a8b1-ee44dbccbbd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhigh_level\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_text\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwidgets\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, clear_output\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfminer'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import FileUpload\n",
    "\n",
    "# Function to extract text from PDF (same as before)\n",
    "def extract_text_from_pdf(file_path):\n",
    "    try:\n",
    "        text = extract_text(file_path)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract basic details (same as before)\n",
    "def extract_basic_details(text):\n",
    "    details = {\n",
    "        \"Name\": None,\n",
    "        \"Phone Number\": None,\n",
    "        \"Email\": None,\n",
    "        \"LinkedIn\": None,\n",
    "        \"GitHub\": None,\n",
    "    }\n",
    "    # Extract email, phone, LinkedIn, GitHub, and Name (same as before)\n",
    "    return details\n",
    "\n",
    "# Function to extract skills from text (same as before)\n",
    "def extract_skills(text, skills):\n",
    "    text = text.lower()\n",
    "    extracted_skills = []\n",
    "    for skill in skills:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text):\n",
    "            extracted_skills.append(skill)\n",
    "    return extracted_skills\n",
    "\n",
    "# Function to extract job description skills (same as before)\n",
    "def extract_job_description_skills(job_description):\n",
    "    skills = []\n",
    "    skills_match = re.findall(r\"\\b(?:Python|SQL|Machine Learning|TensorFlow|Scikit-Learn|MongoDB)\\b\", job_description, re.IGNORECASE)\n",
    "    skills = list(set(skills_match))  # Remove duplicates\n",
    "    return skills\n",
    "\n",
    "# Function to process resumes based on job description (same as before)\n",
    "def process_resumes(resume_folder, job_description):\n",
    "    results = []\n",
    "    job_skills = extract_job_description_skills(job_description)\n",
    "    for file_name in os.listdir(resume_folder):\n",
    "        file_path = os.path.join(resume_folder, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            extracted_text = extract_text_from_pdf(file_path)\n",
    "            if not extracted_text:\n",
    "                continue\n",
    "\n",
    "            basic_details = extract_basic_details(extracted_text)\n",
    "            resume_skills = extract_skills(extracted_text, job_skills)\n",
    "            # Other extraction logic (projects, research papers, CGPA)\n",
    "            total_score = 100  # Dummy score, replace with your actual score calculation logic\n",
    "            results.append({\n",
    "                \"File Name\": file_name,\n",
    "                \"Name\": basic_details[\"Name\"],\n",
    "                \"Total Score\": total_score\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.sort_values(by=\"Total Score\", ascending=False).reset_index(drop=True)\n",
    "    return df_results\n",
    "\n",
    "# Define the interactive interface for Jupyter Notebook\n",
    "def create_interface():\n",
    "    # Widgets\n",
    "    job_desc_input = widgets.Textarea(\n",
    "        description=\"Job Description:\",\n",
    "        layout=widgets.Layout(width='100%', height='150px')\n",
    "    )\n",
    "    folder_button = widgets.Button(description=\"Upload Resume Folder\")\n",
    "    process_button = widgets.Button(description=\"Process Resumes\")\n",
    "    result_output = widgets.Output()\n",
    "    save_button = widgets.Button(description=\"Save Results to CSV\")\n",
    "\n",
    "    # Variables\n",
    "    resume_folder = None\n",
    "    results = None\n",
    "\n",
    "    # Function to handle folder upload (via file upload)\n",
    "    def on_folder_upload(change):\n",
    "        nonlocal resume_folder\n",
    "        if change.new:\n",
    "            resume_folder = change.new[0]['name']\n",
    "            print(f\"Folder selected: {resume_folder}\")\n",
    "\n",
    "    # Handle processing resumes\n",
    "    def process_resumes_button_click(b):\n",
    "        nonlocal results\n",
    "        job_description = job_desc_input.value.strip()\n",
    "        if not job_description:\n",
    "            with result_output:\n",
    "                print(\"Please enter a job description.\")\n",
    "            return\n",
    "\n",
    "        if not resume_folder:\n",
    "            with result_output:\n",
    "                print(\"Please upload a folder containing resumes.\")\n",
    "            return\n",
    "\n",
    "        results = process_resumes(resume_folder, job_description)\n",
    "\n",
    "        with result_output:\n",
    "            clear_output(wait=True)\n",
    "            if results.empty:\n",
    "                print(\"No resumes found.\")\n",
    "            else:\n",
    "                display(results)\n",
    "\n",
    "    # Handle saving the results to a CSV file\n",
    "    def save_results_button_click(b):\n",
    "        if results is not None:\n",
    "            file_name = widgets.FileChooser().show()\n",
    "            file_name = file_name[0].path\n",
    "            results.to_csv(file_name, index=False)\n",
    "            with result_output:\n",
    "                print(f\"Results saved to {file_name}\")\n",
    "        else:\n",
    "            with result_output:\n",
    "                print(\"No results to save.\")\n",
    "\n",
    "    # Connect button events\n",
    "    folder_button.on_click(on_folder_upload)\n",
    "    process_button.on_click(process_resumes_button_click)\n",
    "    save_button.on_click(save_results_button_click)\n",
    "\n",
    "    # Display interface\n",
    "    display(job_desc_input, folder_button, process_button, result_output, save_button)\n",
    "\n",
    "# Start the interface\n",
    "create_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e16ff0-7e16-4958-991e-eea390fd5924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d11e69c5a14282ab3d7660963a1ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Job Description:', placeholder='Enter job description here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3626ba4fb7b2428a9875e9062d6826d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process Resumes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    try:\n",
    "        text = extract_text(file_path)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract basic details\n",
    "def extract_basic_details(text):\n",
    "    details = {\n",
    "        \"Name\": None,\n",
    "        \"Phone Number\": None,\n",
    "        \"Email\": None,\n",
    "        \"LinkedIn\": None,\n",
    "        \"GitHub\": None,\n",
    "    }\n",
    "\n",
    "    # Extract email\n",
    "    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zAZ0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
    "    details[\"Email\"] = email_match.group(0) if email_match else \"Not Found\"\n",
    "\n",
    "    # Extract phone number\n",
    "    phone_match = re.search(r\"\\b\\d{10}\\b|\\+\\d{1,3}\\s?\\d{10}\\b\", text)\n",
    "    details[\"Phone Number\"] = phone_match.group(0) if phone_match else \"Not Found\"\n",
    "\n",
    "    # Extract LinkedIn\n",
    "    linkedin_match = re.search(r\"(https?://)?(www\\.)?linkedin\\.com/in/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"LinkedIn\"] = linkedin_match.group(0) if linkedin_match else \"Not Found\"\n",
    "\n",
    "    # Extract GitHub\n",
    "    github_match = re.search(r\"(https?://)?(www\\.)?github\\.com/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"GitHub\"] = github_match.group(0) if github_match else \"Not Found\"\n",
    "\n",
    "    # Extract name (assumes first line in text is the name)\n",
    "    lines = text.splitlines()\n",
    "    details[\"Name\"] = lines[0].strip() if lines else \"Not Found\"\n",
    "\n",
    "    return details\n",
    "\n",
    "# Function to extract skills from text\n",
    "def extract_skills(text, skills):\n",
    "    text = text.lower()\n",
    "    extracted_skills = []\n",
    "    for skill in skills:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text):\n",
    "            extracted_skills.append(skill)\n",
    "    return extracted_skills\n",
    "\n",
    "# Function to extract CGPA\n",
    "def extract_cgpa(text):\n",
    "    cgpa_match = re.search(r\"\\bCGPA[:\\s]+(\\d+\\.\\d+)\\b\", text, re.IGNORECASE)\n",
    "    return float(cgpa_match.group(1)) if cgpa_match else 0.0\n",
    "\n",
    "# Function to extract additional criteria (projects, research papers)\n",
    "def extract_additional_criteria(text):\n",
    "    projects_count = len(re.findall(r\"\\bproject\\b\", text, re.IGNORECASE))\n",
    "    research_papers_count = len(re.findall(r\"\\bpublication|research paper\\b\", text, re.IGNORECASE))\n",
    "    return projects_count, research_papers_count\n",
    "\n",
    "# Function to extract skills from job description\n",
    "def extract_job_description_skills(job_description):\n",
    "    skills = []\n",
    "    skills_match = re.findall(r\"\\b(?:Python|SQL|Machine Learning|TensorFlow|Scikit-Learn|MongoDB)\\b\", job_description, re.IGNORECASE)\n",
    "    skills = list(set(skills_match))  # Remove duplicates\n",
    "    return skills\n",
    "\n",
    "# Function to process and rank resumes\n",
    "def process_resumes(resume_folder, job_description):\n",
    "    results = []\n",
    "    job_skills = extract_job_description_skills(job_description)\n",
    "    print(f\"Extracted skills from job description: {job_skills}\")\n",
    "\n",
    "    for file_name in os.listdir(resume_folder):\n",
    "        file_path = os.path.join(resume_folder, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            print(f\"Processing: {file_name}\")\n",
    "            extracted_text = extract_text_from_pdf(file_path)\n",
    "            if not extracted_text:\n",
    "                print(f\"Failed to extract text from {file_name}\")\n",
    "                continue\n",
    "\n",
    "            basic_details = extract_basic_details(extracted_text)\n",
    "            resume_skills = extract_skills(extracted_text, job_skills)\n",
    "            projects_count, research_papers_count = extract_additional_criteria(extracted_text)\n",
    "            cgpa = extract_cgpa(extracted_text)\n",
    "\n",
    "            required_matches = [skill for skill in job_skills if skill in resume_skills]\n",
    "            required_score = len(required_matches) * 10\n",
    "            additional_score = (projects_count * 5) + (research_papers_count * 10)\n",
    "            cgpa_score = cgpa * 10  # Scale CGPA to a score (e.g., CGPA 9.0 gives 90 points)\n",
    "\n",
    "            total_score = required_score + additional_score + cgpa_score\n",
    "            max_score = (len(job_skills) * 10) + (5 * 5) + (10 * 5) + 100\n",
    "\n",
    "            relevance_percentage = (total_score / max_score * 100) if max_score > 0 else 0\n",
    "\n",
    "            results.append({\n",
    "                \"File Name\": file_name,\n",
    "                \"Name\": basic_details[\"Name\"],\n",
    "                \"Email\": basic_details[\"Email\"],\n",
    "                \"Phone\": basic_details[\"Phone Number\"],\n",
    "                \"Required Matches\": required_matches,\n",
    "                \"Projects Count\": projects_count,\n",
    "                \"Research Papers Count\": research_papers_count,\n",
    "                \"CGPA\": cgpa,\n",
    "                \"Total Score\": total_score,\n",
    "                \"Relevance Percentage\": relevance_percentage\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.sort_values(by=\"Total Score\", ascending=False).reset_index(drop=True)\n",
    "    df_results['Rank'] = df_results.index + 1\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# Jupyter interface to upload job description and resumes\n",
    "def upload_and_process():\n",
    "    # Create a widget for job description input\n",
    "    job_desc_widget = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Enter job description here...',\n",
    "        description='Job Description:',\n",
    "        disabled=False\n",
    "    )\n",
    "    display(job_desc_widget)\n",
    "\n",
    "    # Button to process uploaded files\n",
    "    def on_process_button_click(change):\n",
    "        job_description = job_desc_widget.value\n",
    "        \n",
    "        if not job_description:\n",
    "            print(\"Please enter a job description.\")\n",
    "            return\n",
    "        \n",
    "        # Folder where resumes are stored\n",
    "        resume_folder = \"resumes/\"  # Ensure your resumes are in this folder\n",
    "        if not os.path.exists(resume_folder):\n",
    "            print(\"No resumes found in the folder.\")\n",
    "            return\n",
    "        \n",
    "        # Process resumes and display ranked result\n",
    "        ranked_resumes = process_resumes(resume_folder, job_description)\n",
    "        display(ranked_resumes)\n",
    "\n",
    "    # Create a button to trigger processing\n",
    "    process_button = widgets.Button(description=\"Process Resumes\")\n",
    "    process_button.on_click(on_process_button_click)\n",
    "    display(process_button)\n",
    "\n",
    "# Run the interface\n",
    "upload_and_process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144fbb3e-d3c6-4932-b7bd-2f7e75dae85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4294c581106493c91cddad49200aedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Job Description:', placeholder='Enter job description here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5ec41bbdd4408d9eaf1ee4127d9e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process Resumes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    try:\n",
    "        print(f\"Extracting text from {file_path}...\")  # Debugging statement\n",
    "        text = extract_text(file_path)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract basic details\n",
    "def extract_basic_details(text):\n",
    "    details = {\n",
    "        \"Name\": None,\n",
    "        \"Phone Number\": None,\n",
    "        \"Email\": None,\n",
    "        \"LinkedIn\": None,\n",
    "        \"GitHub\": None,\n",
    "    }\n",
    "\n",
    "    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zAZ0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
    "    details[\"Email\"] = email_match.group(0) if email_match else \"Not Found\"\n",
    "\n",
    "    phone_match = re.search(r\"\\b\\d{10}\\b|\\+\\d{1,3}\\s?\\d{10}\\b\", text)\n",
    "    details[\"Phone Number\"] = phone_match.group(0) if phone_match else \"Not Found\"\n",
    "\n",
    "    linkedin_match = re.search(r\"(https?://)?(www\\.)?linkedin\\.com/in/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"LinkedIn\"] = linkedin_match.group(0) if linkedin_match else \"Not Found\"\n",
    "\n",
    "    github_match = re.search(r\"(https?://)?(www\\.)?github\\.com/[a-zA-Z0-9-_/]+\", text)\n",
    "    details[\"GitHub\"] = github_match.group(0) if github_match else \"Not Found\"\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    details[\"Name\"] = lines[0].strip() if lines else \"Not Found\"\n",
    "\n",
    "    return details\n",
    "\n",
    "# Function to extract skills from text\n",
    "def extract_skills(text, skills):\n",
    "    text = text.lower()\n",
    "    extracted_skills = []\n",
    "    for skill in skills:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text):\n",
    "            extracted_skills.append(skill)\n",
    "    return extracted_skills\n",
    "\n",
    "# Function to extract CGPA\n",
    "def extract_cgpa(text):\n",
    "    cgpa_match = re.search(r\"\\bCGPA[:\\s]+(\\d+\\.\\d+)\\b\", text, re.IGNORECASE)\n",
    "    return float(cgpa_match.group(1)) if cgpa_match else 0.0\n",
    "\n",
    "# Function to extract additional criteria (projects, research papers)\n",
    "def extract_additional_criteria(text):\n",
    "    projects_count = len(re.findall(r\"\\bproject\\b\", text, re.IGNORECASE))\n",
    "    research_papers_count = len(re.findall(r\"\\bpublication|research paper\\b\", text, re.IGNORECASE))\n",
    "    return projects_count, research_papers_count\n",
    "\n",
    "# Function to extract skills from job description\n",
    "def extract_job_description_skills(job_description):\n",
    "    skills = []\n",
    "    skills_match = re.findall(r\"\\b(?:Python|SQL|Machine Learning|TensorFlow|Scikit-Learn|MongoDB)\\b\", job_description, re.IGNORECASE)\n",
    "    skills = list(set(skills_match))  # Remove duplicates\n",
    "    return skills\n",
    "\n",
    "# Function to process and rank resumes\n",
    "def process_resumes(resume_folder, job_description):\n",
    "    results = []\n",
    "    job_skills = extract_job_description_skills(job_description)\n",
    "    print(f\"Extracted skills from job description: {job_skills}\")  # Debugging statement\n",
    "\n",
    "    for file_name in os.listdir(resume_folder):\n",
    "        file_path = os.path.join(resume_folder, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            print(f\"Processing resume: {file_name}\")  # Debugging statement\n",
    "            extracted_text = extract_text_from_pdf(file_path)\n",
    "            if not extracted_text:\n",
    "                print(f\"Failed to extract text from {file_name}\")\n",
    "                continue\n",
    "\n",
    "            basic_details = extract_basic_details(extracted_text)\n",
    "            resume_skills = extract_skills(extracted_text, job_skills)\n",
    "            projects_count, research_papers_count = extract_additional_criteria(extracted_text)\n",
    "            cgpa = extract_cgpa(extracted_text)\n",
    "\n",
    "            required_matches = [skill for skill in job_skills if skill in resume_skills]\n",
    "            required_score = len(required_matches) * 10\n",
    "            additional_score = (projects_count * 5) + (research_papers_count * 10)\n",
    "            cgpa_score = cgpa * 10  # Scale CGPA to a score (e.g., CGPA 9.0 gives 90 points)\n",
    "\n",
    "            total_score = required_score + additional_score + cgpa_score\n",
    "            max_score = (len(job_skills) * 10) + (5 * 5) + (10 * 5) + 100\n",
    "\n",
    "            relevance_percentage = (total_score / max_score * 100) if max_score > 0 else 0\n",
    "\n",
    "            results.append({\n",
    "                \"File Name\": file_name,\n",
    "                \"Name\": basic_details[\"Name\"],\n",
    "                \"Email\": basic_details[\"Email\"],\n",
    "                \"Phone\": basic_details[\"Phone Number\"],\n",
    "                \"Required Matches\": required_matches,\n",
    "                \"Projects Count\": projects_count,\n",
    "                \"Research Papers Count\": research_papers_count,\n",
    "                \"CGPA\": cgpa,\n",
    "                \"Total Score\": total_score,\n",
    "                \"Relevance Percentage\": relevance_percentage\n",
    "            })\n",
    "\n",
    "    if results:\n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_results = df_results.sort_values(by=\"Total Score\", ascending=False).reset_index(drop=True)\n",
    "        df_results['Rank'] = df_results.index + 1\n",
    "\n",
    "        # Save to Excel\n",
    "        df_results.to_excel(\"ranked_resumes.xlsx\", index=False)\n",
    "        print(\"Results saved to ranked_resumes.xlsx\")\n",
    "\n",
    "        return df_results\n",
    "    else:\n",
    "        print(\"No resumes processed.\")\n",
    "        return None\n",
    "\n",
    "# Jupyter interface to upload job description and resumes\n",
    "def upload_and_process():\n",
    "    job_desc_widget = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Enter job description here...',\n",
    "        description='Job Description:',\n",
    "        disabled=False\n",
    "    )\n",
    "    display(job_desc_widget)\n",
    "\n",
    "    def on_process_button_click(change):\n",
    "        job_description = job_desc_widget.value\n",
    "        \n",
    "        if not job_description:\n",
    "            print(\"Please enter a job description.\")\n",
    "            return\n",
    "        \n",
    "        resume_folder = \"resumes/\"\n",
    "        if not os.path.exists(resume_folder) or len(os.listdir(resume_folder)) == 0:\n",
    "            print(\"No resumes found in the folder.\")\n",
    "            return\n",
    "        \n",
    "        ranked_resumes = process_resumes(resume_folder, job_description)\n",
    "        if ranked_resumes is not None:\n",
    "            display(ranked_resumes)\n",
    "\n",
    "    process_button = widgets.Button(description=\"Process Resumes\")\n",
    "    process_button.on_click(on_process_button_click)\n",
    "    display(process_button)\n",
    "\n",
    "# Run the interface\n",
    "upload_and_process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84720487-b89c-4795-ba9e-f0445fe0e280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
